# Pipeline ETL Serverless para SimulaÃ§Ã£o de Datalake na AWS â€“ Glue + S3 + Athena

## ğŸ¥ VÃ­deo Demonstrativo  
Para ver todo o processo do projeto em aÃ§Ã£o, assista ao vÃ­deo explicativo:  
ğŸ‘‰ [Clique aqui para assistir ao vÃ­deo no youtube](https://www.youtube.com/watch?v=GXAscrgeP4c) 


---

## ğŸ“Œ DescriÃ§Ã£o do Projeto  
Este projeto demonstra um fluxo completo de **pipeline ETL serverless** utilizando **AWS Glue**, **Amazon S3** e **Amazon Athena**, com o objetivo de simular um **datalake**.  
O projeto simula uma arquitetura tÃ­pica de datalake, onde dados brutos e dados tratados ficam organizados em camadas distintas no S3, e um pipeline ETL processa e integra os dados para anÃ¡lises eficientes.

---

## ğŸ›  Arquitetura  
O fluxo foi projetado para ser totalmente **serverless**, ou seja, sem necessidade de provisionar ou gerenciar servidores, aproveitando serviÃ§os gerenciados da AWS.

**Fluxo resumido:**  
1. **Armazenamento de dados brutos** no S3 (`sourcedata`) â€” camada raw do datalake  
2. **CatalogaÃ§Ã£o** dos arquivos no **AWS Glue Data Catalog** via **Crawler**  
3. **TransformaÃ§Ã£o** no **Glue Studio** (joins, desnormalizaÃ§Ã£o, limpeza) â€” ETL Jobs  
4. **Carga** do resultado final no S3 (`datalake`) em formato Parquet e **particionado** â€” camada curated do datalake  
5. **Consulta otimizada** no Athena

---

## ğŸ“‚ Estrutura do Projeto no S3  
/sourcedata
* clientes_csv.csv
* vendedores_csv.csv
* produtos_csv.csv
* vendas_csv.csv
* itensvenda_csv.csv

/datalake
* status_vendedor=Gold/...
* status_vendedor=Silver/...
* status_vendedor=Platinum/...

/logs

/scripts

/temp

## ğŸ”„ Processo de ETL  
### 1ï¸âƒ£ ExtraÃ§Ã£o  
- Os arquivos originais (clientes, vendedores, produtos, vendas e itens de venda) foram carregados na pasta `sourcedata` no S3.

### 2ï¸âƒ£ TransformaÃ§Ã£o  
No **AWS Glue Studio**, foram realizadas as seguintes etapas:  
- **DesnormalizaÃ§Ã£o**: unificaÃ§Ã£o de todas as tabelas em um Ãºnico dataset.  
- **Joins**: integrando vendas com clientes, vendedores, produtos e itens de venda.  
- **RenomeaÃ§Ã£o de colunas**: para evitar conflitos de nomes iguais.  
- **RemoÃ§Ã£o de colunas desnecessÃ¡rias**: limpeza para melhorar performance e reduzir custo.  
- **Particionamento**: separaÃ§Ã£o por `status_vendedor` para otimizar consultas.

### 3ï¸âƒ£ Carga  
- O dataset final foi salvo no formato **Parquet**, jÃ¡ **particionado**, na pasta `datalake` do S3.

## ğŸ“ Estrutura do RepositÃ³rio  
/evidencias
- prints_s3.png
- prints_glue_crawler.png
- prints_glue_studio.png
- prints_athena.png

/sourcedata
- clientes_csv.csv
- vendedores_csv.csv
- produtos_csv.csv
- vendas_csv.csv
- itensvenda_csv.csv

---

## ğŸ” IAM Role  
- Foi criado um **IAM Role** que concede as permissÃµes necessÃ¡rias para que o Glue acesse os buckets do S3, execute crawlers e jobs com seguranÃ§a.  
- Isso garante que apenas serviÃ§os autorizados possam acessar ou modificar os dados.

---

## ğŸš€ Tecnologias Utilizadas  
- **AWS S3** â€“ Armazenamento de dados brutos e tratados  
- **AWS Glue** â€“ ETL serverless e Data Catalog  
- **AWS Glue Studio** â€“ TransformaÃ§Ãµes visuais  (ETL Jobs)
- **AWS Athena** â€“ Consulta SQL serverless sobre dados no S3  
- **Parquet** â€“ Formato otimizado para consulta e armazenamento

---

## ğŸ“¬ Contato

- [LinkedIn](https://www.linkedin.com/in/kauansilva96/)
- [Biolink](https://biolink.website/socialKauanSilva)
- Email: kauangsilva1996@gmail.com

